<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>sklearn RANSACRegressor Method</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="https://Bolive84.github.io/Blog/Blog_1.html" rel="canonical" />
  <!-- Feed -->
        <link href="https://Bolive84.github.io/Blog/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Benoit's Blog Full Atom Feed" />
          <link href="https://Bolive84.github.io/Blog/feeds/{slug}.atom.xml" type="application/atom+xml" rel="alternate" title="Benoit's Blog Categories Atom Feed" />

  <link href="https://Bolive84.github.io/Blog/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="https://Bolive84.github.io/Blog/theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="RANdom SAmple Consensus (RANSAC) Method: First, a little bit of history: The RANSAC algorithm was first published by Fischler and Bolles...">

    <meta name="author" content="Benoit Olive">





<!-- Open Graph -->
<meta property="og:site_name" content="Benoit's Blog"/>
<meta property="og:title" content="sklearn RANSACRegressor Method"/>
<meta property="og:description" content="RANdom SAmple Consensus (RANSAC) Method: First, a little bit of history: The RANSAC algorithm was first published by Fischler and Bolles..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://Bolive84.github.io/Blog/Blog_1.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2019-09-15 00:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://Bolive84.github.io/Blog/author/benoit-olive.html">
<meta property="article:section" content="misc"/>
<meta property="og:image" content="https://Bolive84.github.io/Blog/assets/images/article_cover.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "sklearn RANSACRegressor Method",
  "headline": "sklearn RANSACRegressor Method",
  "datePublished": "2019-09-15 00:00:00-04:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Benoit Olive",
    "url": "https://Bolive84.github.io/Blog/author/benoit-olive.html"
  },
  "image": "https://Bolive84.github.io/Blog/assets/images/article_cover.jpg",
  "url": "https://Bolive84.github.io/Blog/Blog_1.html",
  "description": "RANdom SAmple Consensus (RANSAC) Method: First, a little bit of history: The RANSAC algorithm was first published by Fischler and Bolles..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" class="has-cover">
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="https://Bolive84.github.io/Blog/" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">sklearn RANSACRegressor Method</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="https://Bolive84.github.io/Blog/author/benoit-olive.html">Benoit Olive</a>
            | <time datetime="Sun 15 September 2019">Sun 15 September 2019</time>
        </span>
        <!-- TODO : Modified check -->
            <div class="post-cover cover" style="background-image: url('https://Bolive84.github.io/Blog/assets/images/article_cover.jpg')">
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <h1>RANdom SAmple Consensus (RANSAC) Method:</h1>
<p><br></p>
<p><strong>First, a little bit of history:</strong></p>
<p>The RANSAC algorithm was first published by Fischler and Bolles at SRI (Stanford Research Institute) International in 1981. They used RANSAC to solve the Location Determination Problem (LDP), where the goal is to determine the points in the space that project onto an image into a set of landmarks with known locations.</p>
<p><strong>Today's usage:</strong></p>
<p>Today, it is typically used for linear and non-linear regression problems and is especially popular in the field of photogrammetric computer vision. Photogrammetry being the science of making measurements from photographs (input to photogrammetry is photographs, and the output is typically a map, a drawing, a measurement, or a 3D model of some real-world object or scene).</p>
<p><strong>Here is a quick description of this method:</strong></p>
<p>RANSAC is a non-deterministic iterative method that estimates the parameters of a machine learning algorithm from a dataset that contains outliers. For that, it divides the points in the dataset into two subsets: 1- outliers 2- inliers.</p>
<p>The process that is used to determine inliers and outliers is the following:</p>
<ol>
<li>RANSAC starts by selecting a subset of points as hypothetical inliers.</li>
<li>After fitting the model to the hypothetical inliers, RANSAC checks which elements in the original dataset are consistent with the model instantiated with the estimated parameters.</li>
<li>Model is refitted with the new inliers</li>
<li>The RANSAC algorithm iteratively repeats until the inlier subset is large enough or reaching to the end of the iteration.</li>
</ol>
<p><strong>RANSAC comes with 2 assumptions:</strong></p>
<ol>
<li>
<p>Data consists of inliers and outliers:
"inliers" will be data whose distribution can be explained by some set of model parameters, which can also be subject to noise, and "outliers" which are data that do not fit the model.</p>
</li>
<li>
<p>Given a set of inliers, there exists a procedure which can estimate the parameters of a model that optimally explains or fits this data.</p>
</li>
</ol>
<p>To show how RANSAC regression works, let's generate some data, throw some outliers in our dataset, and build 2 models a classic Linear Regression Model and a RANSAC Regression Model. To conclude, we will plot both regressors and compare the regression metrics resulting from the 2 models.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Let&#39;s create our set of inliers (n=500), with an x and a y that is 50, plus 2 times x with some random noise around that:</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">50</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span>  <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>


<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.000000</td>
      <td>64.967142</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5.090180</td>
      <td>58.797718</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.180361</td>
      <td>66.837607</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.270541</td>
      <td>75.771381</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.360721</td>
      <td>58.379909</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><span class="c1"># Then, a set of outliers (n=100) with y2 0.5 times x2 with some random noise around too:</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span> <span class="n">x2</span>  <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">x2</span><span class="p">))</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="n">x2</span><span class="p">,</span> <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="n">y2</span><span class="p">})</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># ... And merge our 2 datasets</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>


<p>In the merged dataframe, values in column [A] and column [B] will be respectively our "predictor" and our "target" variables.</p>
<div class="highlight"><pre><span></span><span class="c1"># We can now visualize our data using scatter plots:</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Data Including A Set Of Outliers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predictor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nb">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Target&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="images/output_8_1.png"></p>
<div class="highlight"><pre><span></span><span class="c1"># ... And fit a model using all data and ordinary Linear Regression:</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">linreg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linreg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># Let&#39;s print slope and intercept for our Linear Regression model:</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Slope - Linear Regression:&quot;</span><span class="p">,</span> <span class="n">linreg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Intercept - Linear Regression:&quot;</span><span class="p">,</span> <span class="n">linreg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Slope</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">.</span><span class="mi">82654094</span><span class="p">]</span>
<span class="n">Intercept</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span> <span class="mi">66</span><span class="p">.</span><span class="mi">34239236618237</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># We can now calculate our predicted value &#39;y hat&#39;:</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">linreg</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">linreg</span><span class="o">.</span><span class="n">coef_</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># And then plot our Linear Regressor:</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Ordinary Linear Regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s1">&#39;Linear Regressor&#39;</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predictor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="nb">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;Target&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="png" src="images/output_11_1.png"></p>
<div class="highlight"><pre><span></span><span class="c1"># Let&#39;s see how our regression metrics look now:</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">median_absolute_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_log_error</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Squared Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">])))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">])))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Median Absolute Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Root Mean Square Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Square Log Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;R Squared - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">1563</span><span class="p">.</span><span class="mi">1242990198043</span>
<span class="n">Mean</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">29</span><span class="p">.</span><span class="mi">946349872420967</span>
<span class="n">Median</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">21</span><span class="p">.</span><span class="mi">985884617753833</span>
<span class="n">Root</span> <span class="n">Mean</span> <span class="n">Square</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">39</span><span class="p">.</span><span class="mi">5363667908396</span>
<span class="n">Mean</span> <span class="n">Square</span> <span class="n">Log</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">4990655738288573</span>
<span class="n">R</span> <span class="n">Squared</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">06861415661215686</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># The next step will be to fit linear model with RANSAC algorithm:</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RANSACRegressor</span>

<span class="n">ransac</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">RANSACRegressor</span><span class="p">()</span>
<span class="n">ransac</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">inlier_mask</span> <span class="o">=</span> <span class="n">ransac</span><span class="o">.</span><span class="n">inlier_mask_</span>
<span class="n">outlier_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">inlier_mask</span><span class="p">)</span>

<span class="c1"># We can now compare estimated Coefficients and Intercepts resulting from our 2 regression models:</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Slope, Intercept:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Linear Regression: &quot;</span><span class="p">,</span> <span class="n">linreg</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">linreg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;RANSAC Regression: &quot;</span> <span class="p">,</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">coef_</span> <span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Slope</span><span class="p">,</span> <span class="n">Intercept</span><span class="p">:</span>
<span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="p">[</span><span class="mi">0</span><span class="p">.</span><span class="mi">82654094</span><span class="p">]</span> <span class="p">,</span> <span class="mi">66</span><span class="p">.</span><span class="mi">34239236618237</span>
<span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="p">[</span><span class="mi">2</span><span class="p">.</span><span class="mi">01751038</span><span class="p">]</span> <span class="p">,</span> <span class="mi">49</span><span class="p">.</span><span class="mi">361073815170585</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># And calculate our &#39;y hat&#39; for the RANSAC Regression in order to plot the RANSAC Regressor:</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Yhat_ransac&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">+</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">coef_</span> <span class="o">*</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Let&#39;s plot our RANSAC Regressor, and see if it is robust to outliers:</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Yhat_ransac&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;RANSAC Regression Is Robust To Outliers&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s1">&#39;RANSAC Regressor&#39;</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predictor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="images/output_15_0.png"></p>
<div class="highlight"><pre><span></span><span class="c1"># We can now show our 2 regressors on the same plot in order to visulaize the difference between our 2 models:   </span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span><span class="s1">&#39;gold&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Yhat_ransac&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear VS. RANSAC Regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">legend</span><span class="p">((</span><span class="s1">&#39;Linear Regressor&#39;</span> <span class="p">,</span> <span class="s1">&#39;RANSAC Regressor&#39;</span><span class="p">,</span> <span class="s1">&#39;Data&#39;</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Predictor&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">);</span>
</pre></div>


<p><img alt="png" src="images/output_16_0.png"></p>
<p>As we can see on the above plot, when ordinary Linear Regression is influenced by outliers, RANSAC isn't.
RANSAC algorythm takes the complete input, separates inliers from outliers and build a model that is estimated only from the determined inliers (see ordinary Linear Regressor in red vs. green RANSAC Regressor in green)  </p>
<div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">inlier_mask</span> <span class="o">=</span> <span class="n">ransac</span><span class="o">.</span><span class="n">inlier_mask_</span>
<span class="n">X_accpt</span><span class="p">,</span> <span class="n">Y_accpt</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">inlier_mask</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">inlier_mask</span><span class="p">]</span>
<span class="n">Y_predict</span> <span class="o">=</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">coef_</span> <span class="o">*</span> <span class="n">X_accpt</span> <span class="o">+</span> <span class="n">ransac</span><span class="o">.</span><span class="n">estimator_</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="c1"># Finally let&#39;s compare our regression metrics, and see which model performs better:</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Regression Metrics :&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Squared Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">])))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Squared Error - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">])))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Median Absolute Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Median Absolute Error - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="n">median_absolute_error</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Root Mean Square Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Root Mean Square Error - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">))))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Square Log Error - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Mean Square Log Error - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;R Squared - Linear Regression: &#39;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;B&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Linear_Yhat&#39;</span><span class="p">]))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;R Squared - RANSAC Regression: &#39;</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">Y_accpt</span><span class="p">,</span> <span class="n">Y_predict</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="n">Regression</span> <span class="n">Metrics</span> <span class="p">:</span>

<span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">1563</span><span class="p">.</span><span class="mi">1242990198043</span>
<span class="n">Mean</span> <span class="n">Squared</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">86</span><span class="p">.</span><span class="mi">32715034438624</span>

<span class="n">Mean</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">29</span><span class="p">.</span><span class="mi">946349872420967</span>
<span class="n">Mean</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">7</span><span class="p">.</span><span class="mi">53403298028855</span>

<span class="n">Median</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">21</span><span class="p">.</span><span class="mi">985884617753833</span>
<span class="n">Median</span> <span class="k">Absolute</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">6</span><span class="p">.</span><span class="mi">564924468214095</span>

<span class="n">Root</span> <span class="n">Mean</span> <span class="n">Square</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">39</span><span class="p">.</span><span class="mi">5363667908396</span>
<span class="n">Root</span> <span class="n">Mean</span> <span class="n">Square</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">9</span><span class="p">.</span><span class="mi">291240516980832</span>

<span class="n">Mean</span> <span class="n">Square</span> <span class="n">Log</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">4990655738288573</span>
<span class="n">Mean</span> <span class="n">Square</span> <span class="n">Log</span> <span class="n">Error</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">009578999086090615</span>

<span class="n">R</span> <span class="n">Squared</span> <span class="o">-</span> <span class="n">Linear</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">06861415661215686</span>
<span class="n">R</span> <span class="n">Squared</span> <span class="o">-</span> <span class="n">RANSAC</span> <span class="n">Regression</span><span class="p">:</span>  <span class="mi">0</span><span class="p">.</span><span class="mi">8891918079356032</span>
</pre></div>


<p>When comparing the different regression metrics, we can see that RANSAC algorythm can boost our model scores when the dataset includes a significant amount of outliers. In this specifc case, all the regression metrics scores have improved significantly.  The difference is particularly obervable on R2 score which reaches almost 89% with RANSAC regression model, when its score was below 7% with the ordinary Linear Regression model.  </p>
<h2>Conclusion:</h2>
<p><strong>Pros:</strong></p>
<p>Linear regression models can be heavily impacted by the presence of outliers, which can come for instance from extreme values of the noise, or erroneous measurements. RANdom SAmple Consensus (RANSAC) algorithm can be used to remove sets of points from your model that do not follow the dominant pattern of the data, and as a robust machine learning algorithm, RANSAC will improve the performance of your model by estimating the parameters with a high degree of accuracy, even when a significant number of outliers are present in the data set.</p>
<p><strong>Cons:</strong></p>
<p>RANSAC usually performs poorly when the number of inliers in the dataset is less than 50%. Also, when the noise threshold is too small, the estimated parameters tend to be unstable. Finally, this algorithm removes data from the model, and in general losing data when developing models is something we want to avoid.</p>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=sklearn RANSACRegressor Method&amp;url=https://Bolive84.github.io/Blog/Blog_1.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://Bolive84.github.io/Blog/Blog_1.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=https://Bolive84.github.io/Blog/Blog_1.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>


                <div class="clear"></div>


                </section>


                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">Theme <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila</a></span>
          <span class="credits-software">Published with <a href="https://github.com/getpelican/pelican" rel="nofollow">Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="https://Bolive84.github.io/Blog/theme/js/script.js"></script>

</body>
</html>