{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we need Data Generators?\n",
    "\n",
    "Data generators help us create data with different distributions and profiles to experiment on. If you are testing various algorithms available to you and you want to find which one works in what cases, then these data generators can help you generate case specific data and then test the algorithm.\n",
    "\n",
    "For example you want to check whether gradient boosting trees can do well given just 100 data-points and 2 features? Now either you can search for a 100 data-points dataset, or you can use your own dataset that you are working on. But how would you know if the classifier was a good choice, given that you have so less data and doing cross validation and testing still leaves fair chance of overfitting? Or rather you could use generated data and see what usually works well for such a case, a boosting algorithm or a linear model.\n",
    "\n",
    "Few reasons why you need generated data\n",
    "Can your models handle noisy labels?\n",
    "What happens when 99% of your labels are negative and only 1% are positive?\n",
    "if your models can tell you which features are redundant?\n",
    "In case of model provided feature importances how does the model handle redundant features.\n",
    "Does removing redundant features improve your model’s performance?\n",
    "How does your model behave when Redundant features, noise and imbalance are all present at once in your dataset?\n",
    "If you have N datapoints and M features, what are the safe values of N,M so your model doesn’t overfit?\n",
    "\n",
    "Finding a real dataset meeting such combination of criterias with known levels will be very difficult. As a result we take into account few capabilities that a generator must have to give good approximations of real world datasets.\n",
    "\n",
    "Generator Capabilities\n",
    "\n",
    "While looking for generators we look for certain capabilities. I list the important capabilities that we look for in generators and classify them accordingly.\n",
    "\n",
    "Supports Imbalancing the Classes\n",
    "\n",
    "A lot of times you will get classification data that has huge imbalance. For example fraud detection has imbalance such that most examples (99%) are non-fraud. To check how your classifier does in imbalanced cases, you need to have ability to generate multiple types of imbalanced data.\n",
    "\n",
    "Guassian Quantiles\n",
    "Make classification API\n",
    "Support Generating Noisy Data\n",
    "\n",
    "Can your classifier perform its job even if the class labels are noisy. What if some fraud examples are marked non-fraud and some non-fraud are marked fraud? How do you know your chosen classifiers behaviour in presence of noise? And how do you select a Robust classifier?\n",
    "\n",
    "Make classification API\n",
    "\n",
    "Adding Redundant/Useless features\n",
    "\n",
    "These are Linear Combinations of your useful features. Many Models like Linear Regression give arbitrary feature coefficient for correlated features. In case of Tree Models they mess up feature importance and also use these features randomly and interchangeably for splits. Removing correlated features usually improves performance.\n",
    "\n",
    "Make classification API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
